{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression #F-value between label/feature for regression tasks.\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from xgboost import XGBRegressor\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_metrics_2020 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40560, 82)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nasdaq100_padding.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split(data_ready, lookback, test_length):\n",
    "    \n",
    "    data = data_ready.iloc[-test_length-lookback:,:]\n",
    "    length = data.shape[0]\n",
    "    train_starts = np.arange(0, length - lookback,1)\n",
    "    # to make the train_starts and test_starts have the same number of elements\n",
    "    test_starts = np.arange(lookback, length + 1, 1)[:len(train_starts)] \n",
    "    trains = [data.iloc[s:s+lookback] for s in train_starts]\n",
    "    tests = [data.iloc[s:s+1] for s in test_starts]\n",
    "    print('Split Done. Train Start')\n",
    "    #print('training set len:', len(trains))\n",
    "    #print('test set len:', len(tests))\n",
    "    return trains, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag_diff(raw_data, order, target, exo=True):\n",
    "    p = order - 1 \n",
    "    X = raw_data.copy()\n",
    "    # Generate lag variables \n",
    "    composite_col = X.columns[X.columns != target]\n",
    "    X['y_pch'] = X[target].diff()\n",
    "    X['y_pch_true'] = X['y_pch'].shift(-1)\n",
    "\n",
    "    if exo:\n",
    "        X[composite_col + '_pch'] = X[composite_col].diff()\n",
    "        # make lag p variables and drop\n",
    "        for i in range(0, p):\n",
    "            X['y_pch_' + str(i+1)] = X['y_pch'].shift(i+1)\n",
    "            X[composite_col + ('_' + str(i+1))] = X[composite_col + '_pch'].shift(i+1)      \n",
    "    else:\n",
    "        for i in range(0, p):\n",
    "            X['y_pch_' + str(i+1)] = X['y_pch'].shift(i+1)\n",
    "\n",
    "    # drop price series\n",
    "    # don't drop target because we need to compare later\n",
    "    X.drop(columns=composite_col, inplace=True) \n",
    "    X.dropna(inplace=True)\n",
    "    print('Lag %d Diff Generated' %order)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_pred(raw_data, order, test_length, target, exo=True):\n",
    "    X = raw_data.copy()\n",
    "\n",
    "    # generate diff and its lag variables\n",
    "    data = get_lag_diff(X, 1, target)\n",
    "\n",
    "    # dict for models    \n",
    "    params_ols = {'fit_intercept': [True, False]}\n",
    "    params_rl = {'alpha':[0.01, 0.05, 0.1, 0.3, 0.5, 1, 5, 10, 20, 100, 200, 300]}\n",
    "    params_dim = {'n_components': [2,3,5,10,20]}\n",
    "    params_rfr = {'n_estimators':[5,10,20],\n",
    "               'max_depth':[5,10,20],\n",
    "               'min_samples_leaf' :[1,5,10],\n",
    "               'max_leaf_nodes' :[5,10, 15]\n",
    "               }\n",
    "    params_xgr = {'n_estimators': [5, 10, 20],\n",
    "              'min_child_weight': [10, 50, 100],\n",
    "              'gamma': [0, 0.5, 1, 2, 5],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'max_depth': [3, 4, 5]\n",
    "              }\n",
    "    models = {\n",
    "            'PCA': GridSearchCV(LinearRegression(), \n",
    "                               param_grid=params_ols, iid='deprecated', cv=5),\n",
    "            'XGR': GridSearchCV(XGBRegressor(objective='reg:squarederror'),\n",
    "                                param_grid=params_xgr, iid='deprecated', cv=3),\n",
    "            'RFR': GridSearchCV(RandomForestRegressor(), \n",
    "                               param_grid=params_rfr, iid='deprecated', cv=3),\n",
    "            'OLS': GridSearchCV(LinearRegression(), \n",
    "                               param_grid=params_ols, iid='deprecated', cv=5),\n",
    "            'LR': GridSearchCV(Lasso(), \n",
    "                               param_grid=params_rl, iid='deprecated', cv=5),\n",
    "            'RR': GridSearchCV(Ridge(), \n",
    "                               param_grid=params_rl, iid='deprecated', cv=5),\n",
    "            'PLS': GridSearchCV(PLSRegression(), \n",
    "                               param_grid=params_dim, iid='deprecated', cv=5)\n",
    "            }\n",
    "\n",
    "    pred_result = {}\n",
    "    df_err_model = pd.DataFrame([])\n",
    "    lookback1 = [30, 50, 100, 500, 1000, 3000, 6000, 10000, 12000, 15000]\n",
    "    lookback2 = [500, 1000, 3000, 6000, 10000, 12000, 15000]\n",
    "    pca_num = np.array([])\n",
    "    \n",
    "    for m in models:\n",
    "        \n",
    "        min_score = -100000\n",
    "        print('Model %s Start' %m)\n",
    "        pred_price_best = np.array([])\n",
    "        if m =='XGR' or m == 'RFR':\n",
    "            lookback = lookback2\n",
    "        else:\n",
    "            lookback = lookback1\n",
    "            \n",
    "        for n in lookback:\n",
    "\n",
    "            # split the data with different lookback n\n",
    "            trains, tests = get_data_split(data_ready = data, lookback = n, test_length = test_length)\n",
    "            print('Lookback : %d' %n)\n",
    "\n",
    "            pred_price = np.array([])\n",
    "            \n",
    "            true_price = np.array([])\n",
    "\n",
    "            for i in range(len(trains)):\n",
    "                \n",
    "                iteration_start = time.monotonic()\n",
    "                X_train = trains[i].drop(columns=['y_pch_true', target])\n",
    "                X_test = tests[i].drop(columns=['y_pch_true', target])\n",
    "                Y_train = trains[i]['y_pch_true']\n",
    "                   \n",
    "                if m == 'PLS':\n",
    "                    X_train_mean = np.mean(X_train, axis=0)\n",
    "                    X_train = X_train-X_train_mean\n",
    "                    X_test = tests[i].drop(columns=['y_pch_true', target]).values - X_train_mean[np.newaxis,:] # centered for test set\n",
    "                    model_fit = models[m].fit(X_train, Y_train) # PLS.fit(X)\n",
    "                    selected_params = model_fit.best_params_\n",
    "                    best_model = model_fit.best_estimator_\n",
    "                    pred_diff = best_model.predict(X_test) # we dont have to do: np.matmul(X_test, X_pls.x_loadings_)\n",
    "                \n",
    "                elif m == 'PCA':\n",
    "                    X_train_mean = np.mean(X_train, axis=0)\n",
    "                    X_train = X_train-X_train_mean # centered\n",
    "                    X_test = tests[i].drop(columns=['y_pch_true', target]).values - X_train_mean[np.newaxis,:] # centered for test set\n",
    "                    \n",
    "                    # select best n_component for each train set\n",
    "                    pca_min_score = 100000000\n",
    "                    \n",
    "                  \n",
    "                    for j in [2,3,5,10,20,30]:\n",
    "                        pca_fit = PCA(n_components=j).fit(X_train)\n",
    "                        model_fit = models[m].fit(pca_fit.fit_transform(X_train), Y_train) # OLS.fit on selected PCs\n",
    "                        selected_params = model_fit.best_params_\n",
    "                        best_model = model_fit.best_estimator_\n",
    "                        pred_diff_pca = best_model.predict(np.matmul(X_test, np.transpose(pca_fit.components_))) # loadings\n",
    "                        pca_score = mse(trains[i]['y_pch_true'].iloc[-1:].values, pred_diff_pca)\n",
    "                        \n",
    "                        # update whenevere mse gets smaller\n",
    "                        if pca_score < pca_min_score:\n",
    "                            pca_min_score = pca_score\n",
    "                            pred_diff = pred_diff_pca\n",
    "                            best_j = j\n",
    "                    pca_num = np.append(pca_num, best_j)\n",
    "                    #print('PCA choose %d' %pca_num)\n",
    "\n",
    "                else:\n",
    "                    model_fit = models[m].fit(X_train, Y_train)\n",
    "                    selected_params = model_fit.best_params_\n",
    "                    best_model = model_fit.best_estimator_\n",
    "                    #print('best model selected')\n",
    "                    X_new = SelectFromModel(estimator = best_model, threshold='median').fit(X_train,Y_train)\n",
    "                    #print('best input selected')\n",
    "                    best_model.fit(X_new.transform(X_train),Y_train)\n",
    "                    selected_col = X_train.columns[X_new.get_support()]\n",
    "                    pred_diff = best_model.predict(X_test[selected_col].values)\n",
    "                \n",
    "                \n",
    "                # recover price using predicted difference after feature selection\n",
    "                true_price = np.append(true_price, trains[i][target].iloc[-1:].values+ trains[i]['y_pch_true'].iloc[-1:].values)\n",
    "                pred_price = np.append(pred_price, trains[i][target].iloc[-1:].values + pred_diff)\n",
    "                \n",
    "                iteration_end = time.monotonic()\n",
    "                if(i % 500 == 1):\n",
    "                    print('{:.2f}%'.format(i/(len(trains)+1)*100))\n",
    "                    print(\"Iter time of %s: \" %m, iteration_end - iteration_start)\n",
    "                    print(selected_params)\n",
    "            err_metric = evaluate(true_price, pred_price)\n",
    "            score = err_metric['mda']\n",
    "\n",
    "            if min_score < score:\n",
    "                \n",
    "                print(\"Saving... Score: %f for lookback: %d \" %(score, n))\n",
    "                fname = str(m)+'_best.txt'\n",
    "                f = [true_price, pred_price, n, selected_params]\n",
    "                with open(fname,\"wb\") as fp:\n",
    "                    pickle.dump(f,fp)\n",
    "                pred_price_best = pred_price\n",
    "                min_score = score\n",
    "                print(pred_price_best)\n",
    "            \n",
    "            # save every model with every lookback\n",
    "            fname2 = str(m)+'_'+str(n)+'.txt'\n",
    "            f2 = pred_price\n",
    "            with open(fname2, \"wb\") as fp:\n",
    "                pickle.dump(f2,fp)\n",
    "            \n",
    "            \n",
    "            df = pd.DataFrame(err_metric.items())\n",
    "            df = df.transpose()\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.drop(df.index[[0]]).astype(float) # change to float to use round(3)\n",
    "            df['lookback']=str(n)\n",
    "            df['model']=str(m)\n",
    "            #df.columns = [str(col) + '_' + str(m) for col in df.columns]\n",
    "            df_err_model = df_err_model.append(df, ignore_index = True)\n",
    "            print(df_err_model)\n",
    "            fname3 = 'df_err_model.txt'\n",
    "            with open(fname3,\"wb\") as fp:\n",
    "                pickle.dump(df_err_model,fp)\n",
    "\n",
    "\n",
    "        fname4 = 'pca_num.txt'\n",
    "        with open(fname4,\"wb\") as fp:\n",
    "            pickle.dump(pca_num,fp)\n",
    "        pred_result[m] = pred_price_best\n",
    "        print(pred_price_best.shape)\n",
    "        evaluate(true_price, pred_price_best)\n",
    "\n",
    "    return  true_price, df_err_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test length of 2730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag 1 Diff Generated\n",
      "Model PCA Start\n",
      "Split Done. Train Start\n",
      "Lookback : 30\n",
      "0.04%\n",
      "Iter time of PCA:  0.20300000000861473\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': True}\n",
      "36.65%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': True}\n",
      "54.96%\n",
      "Iter time of PCA:  0.10999999998603016\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.10899999999674037\n",
      "{'fit_intercept': True}\n",
      "91.58%\n",
      "Iter time of PCA:  0.10899999999674037\n",
      "{'fit_intercept': True}\n",
      "Saving... Score: 0.850861 for lookback: 30 \n",
      "[4950.35837264 4950.23894766 4949.42980709 ... 4921.64178004 4921.81989718\n",
      " 4921.86063599]\n",
      "0      rmse       mda      mpda     mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.84964  0.845185  0.856418       30   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 50\n",
      "0.04%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': True}\n",
      "36.65%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  0.14000000001396984\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.10899999999674037\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.869916 for lookback: 50 \n",
      "[4950.28919952 4950.14064053 4949.38040593 ... 4921.67229712 4922.01237432\n",
      " 4922.88157531]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 100\n",
      "0.04%\n",
      "Iter time of PCA:  0.15599999998812564\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.10899999999674037\n",
      "{'fit_intercept': False}\n",
      "36.65%\n",
      "Iter time of PCA:  0.11000000001513399\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  0.139999999984866\n",
      "{'fit_intercept': True}\n",
      "73.27%\n",
      "Iter time of PCA:  0.14000000001396984\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.125\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.886039 for lookback: 100 \n",
      "[4950.26342155 4949.99204805 4949.48918454 ... 4921.55768022 4921.65142801\n",
      " 4922.00435405]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 500\n",
      "0.04%\n",
      "Iter time of PCA:  0.17199999999138527\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.14100000000325963\n",
      "{'fit_intercept': True}\n",
      "36.65%\n",
      "Iter time of PCA:  0.15599999998812564\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  0.15599999998812564\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.15600000001722947\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.15600000001722947\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.890436 for lookback: 500 \n",
      "[4950.52400367 4949.95443592 4949.30370696 ... 4921.57989624 4921.83591643\n",
      " 4922.06098333]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 1000\n",
      "0.04%\n",
      "Iter time of PCA:  0.1879999999946449\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.17199999999138527\n",
      "{'fit_intercept': False}\n",
      "36.65%\n",
      "Iter time of PCA:  0.15600000001722947\n",
      "{'fit_intercept': True}\n",
      "54.96%\n",
      "Iter time of PCA:  0.15600000001722947\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.17199999999138527\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.17199999999138527\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.906193 for lookback: 1000 \n",
      "[4950.29567353 4950.21161568 4949.46046881 ... 4921.57813792 4921.74774501\n",
      " 4922.21407471]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 3000\n",
      "0.04%\n",
      "Iter time of PCA:  0.29699999999138527\n",
      "{'fit_intercept': True}\n",
      "18.34%\n",
      "Iter time of PCA:  0.29699999999138527\n",
      "{'fit_intercept': True}\n",
      "36.65%\n",
      "Iter time of PCA:  0.28100000001722947\n",
      "{'fit_intercept': True}\n",
      "54.96%\n",
      "Iter time of PCA:  0.29699999996228144\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.26500000001396984\n",
      "{'fit_intercept': True}\n",
      "91.58%\n",
      "Iter time of PCA:  0.28100000001722947\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.909491 for lookback: 3000 \n",
      "[4950.3396407  4950.28005549 4949.36764534 ... 4921.60667009 4921.64184615\n",
      " 4922.07034066]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "5  1.199175  0.909491  0.946936  0.873472  0.878032  0.944790     3000   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 6000\n",
      "0.04%\n",
      "Iter time of PCA:  0.5630000000237487\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  0.5\n",
      "{'fit_intercept': False}\n",
      "36.65%\n",
      "Iter time of PCA:  0.5310000000172295\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  0.5470000000204891\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.5469999999622814\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.5\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.932210 for lookback: 6000 \n",
      "[4950.28858003 4950.26898777 4949.32009928 ... 4921.72054782 4921.6123237\n",
      " 4921.98778601]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "5  1.199175  0.909491  0.946936  0.873472  0.878032  0.944790     3000   PCA\n",
      "6  1.262022  0.932210  0.926009  0.938174  0.935094  0.929487     6000   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 10000\n",
      "0.04%\n",
      "Iter time of PCA:  0.9689999999827705\n",
      "{'fit_intercept': True}\n",
      "18.34%\n",
      "Iter time of PCA:  0.8910000000032596\n",
      "{'fit_intercept': True}\n",
      "36.65%\n",
      "Iter time of PCA:  0.9220000000204891\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  0.8910000000032596\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  0.8910000000032596\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  0.9209999999729916\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.941737 for lookback: 10000 \n",
      "[4950.284546   4950.17432961 4949.31151076 ... 4921.70430754 4921.59235147\n",
      " 4921.96138933]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "5  1.199175  0.909491  0.946936  0.873472  0.878032  0.944790     3000   PCA\n",
      "6  1.262022  0.932210  0.926009  0.938174  0.935094  0.929487     6000   PCA\n",
      "7  1.296367  0.941737  0.939507  0.943885  0.941617  0.941852    10000   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 12000\n",
      "0.04%\n",
      "Iter time of PCA:  1.2660000000032596\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  1.0630000000237487\n",
      "{'fit_intercept': False}\n",
      "36.65%\n",
      "Iter time of PCA:  1.0939999999827705\n",
      "{'fit_intercept': True}\n",
      "54.96%\n",
      "Iter time of PCA:  1.125\n",
      "{'fit_intercept': True}\n",
      "73.27%\n",
      "Iter time of PCA:  1.0939999999827705\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  1.077999999979511\n",
      "{'fit_intercept': True}\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "5  1.199175  0.909491  0.946936  0.873472  0.878032  0.944790     3000   PCA\n",
      "6  1.262022  0.932210  0.926009  0.938174  0.935094  0.929487     6000   PCA\n",
      "7  1.296367  0.941737  0.939507  0.943885  0.941617  0.941852    10000   PCA\n",
      "8  1.316418  0.909491  0.919283  0.900072  0.898466  0.920588    12000   PCA\n",
      "Split Done. Train Start\n",
      "Lookback : 15000\n",
      "0.04%\n",
      "Iter time of PCA:  1.422000000020489\n",
      "{'fit_intercept': False}\n",
      "18.34%\n",
      "Iter time of PCA:  1.3900000000139698\n",
      "{'fit_intercept': False}\n",
      "36.65%\n",
      "Iter time of PCA:  1.327999999979511\n",
      "{'fit_intercept': False}\n",
      "54.96%\n",
      "Iter time of PCA:  1.4059999999590218\n",
      "{'fit_intercept': False}\n",
      "73.27%\n",
      "Iter time of PCA:  1.3130000000237487\n",
      "{'fit_intercept': False}\n",
      "91.58%\n",
      "Iter time of PCA:  1.327999999979511\n",
      "{'fit_intercept': False}\n",
      "Saving... Score: 0.946134 for lookback: 15000 \n",
      "[4950.32988234 4950.18804988 4949.29392534 ... 4921.67131182 4921.62725279\n",
      " 4921.92079237]\n",
      "0      rmse       mda      mpda      mnda       mpp       mnp lookback model\n",
      "0  0.935479  0.850861  0.852128  0.849640  0.845185  0.856418       30   PCA\n",
      "1  0.948833  0.869916  0.868559  0.871223  0.866617  0.873107       50   PCA\n",
      "2  1.015010  0.886039  0.889470  0.882734  0.879616  0.892364      100   PCA\n",
      "3  1.091519  0.890436  0.886482  0.894245  0.889805  0.891039      500   PCA\n",
      "4  1.107218  0.906193  0.896191  0.915827  0.911162  0.901558     1000   PCA\n",
      "5  1.199175  0.909491  0.946936  0.873472  0.878032  0.944790     3000   PCA\n",
      "6  1.262022  0.932210  0.926009  0.938174  0.935094  0.929487     6000   PCA\n",
      "7  1.296367  0.941737  0.939507  0.943885  0.941617  0.941852    10000   PCA\n",
      "8  1.316418  0.909491  0.919283  0.900072  0.898466  0.920588    12000   PCA\n",
      "9  1.318227  0.946134  0.953697  0.938849  0.937592  0.954645    15000   PCA\n",
      "(2730,)\n",
      "Model XGR Start\n",
      "Split Done. Train Start\n",
      "Lookback : 500\n",
      "0.04%\n",
      "Iter time of XGR:  92.85899999999674\n",
      "{'colsample_bytree': 1.0, 'gamma': 0, 'max_depth': 3, 'min_child_weight': 100, 'n_estimators': 20, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "true_price, df_err_model = get_moving_pred(raw_data= df, order=1, test_length=2730, target='NDX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PCA_best.txt',\"rb\") as fp:\n",
    "    PCA_best = pickle.load(fp) \n",
    "with open('PCA_best.txt',\"rb\") as fp:\n",
    "    PCA_best = pickle.load(fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(PCA_best[0]) # true\n",
    "plt.plot(PCA_best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(PCA_best[0], PCA_best[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
